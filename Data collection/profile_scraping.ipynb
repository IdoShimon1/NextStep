{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q selenium undetected-chromedriver pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "# ---------------- SETUP: START BROWSER ----------------\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Remove this for debugging\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "driver = uc.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# ---------------- LOGIN FUNCTION ----------------\n",
    "def linkedin_login(email, password):\n",
    "    driver.get(\"https://www.linkedin.com/login\")\n",
    "    time.sleep(random.uniform(3, 5))\n",
    "\n",
    "    # Enter credentials\n",
    "    email_input = driver.find_element(By.ID, \"username\")\n",
    "    password_input = driver.find_element(By.ID, \"password\")\n",
    "    email_input.send_keys(email)\n",
    "    password_input.send_keys(password)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "\n",
    "    time.sleep(random.uniform(5, 8))  # Wait for login to complete\n",
    "\n",
    "# ---------------- SEARCH FOR PEOPLE BY JOB TITLE ----------------\n",
    "def search_profiles(job_title, num_pages=2):\n",
    "    \"\"\"Search for LinkedIn profiles based on job title\"\"\"\n",
    "    profiles = []\n",
    "    search_url = f\"https://www.linkedin.com/search/results/people/?keywords={job_title.replace(' ', '%20')}\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(random.uniform(4, 7))\n",
    "\n",
    "    for _ in range(num_pages):  # Loop through multiple pages\n",
    "        profile_links = driver.find_elements(By.XPATH, \"//a[contains(@href, '/in/')]\")\n",
    "        for link in profile_links:\n",
    "            profile_url = link.get_attribute(\"href\")\n",
    "            if profile_url and \"linkedin.com/in/\" in profile_url:\n",
    "                profiles.append(profile_url)\n",
    "\n",
    "        # Go to next page\n",
    "        try:\n",
    "            next_button = driver.find_element(By.XPATH, \"//button[@aria-label='Next']\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "        except:\n",
    "            break  # No more pages\n",
    "\n",
    "    return list(set(profiles))  # Remove duplicates\n",
    "\n",
    "# ---------------- SCRAPE LINKEDIN PROFILE ----------------\n",
    "def scrape_profile(profile_url):\n",
    "    driver.get(profile_url)\n",
    "    time.sleep(random.uniform(4, 7))\n",
    "\n",
    "    # Extract Name\n",
    "    try:\n",
    "        name = driver.find_element(By.TAG_NAME, \"h1\").text\n",
    "    except:\n",
    "        name = \"Unknown\"\n",
    "\n",
    "    # Extract Job Positions\n",
    "    jobs = []\n",
    "    try:\n",
    "        job_elements = driver.find_elements(By.XPATH, \"//div[contains(@class,'experience__list-item')]\")\n",
    "        for job in job_elements:\n",
    "            job_title = job.find_element(By.TAG_NAME, \"h3\").text\n",
    "            company = job.find_element(By.TAG_NAME, \"p\").text\n",
    "            jobs.append(f\"{job_title} at {company}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Extract Education\n",
    "    education = []\n",
    "    try:\n",
    "        edu_elements = driver.find_elements(By.XPATH, \"//section[contains(@id,'education-section')]//li\")\n",
    "        for edu in edu_elements:\n",
    "            school = edu.find_element(By.TAG_NAME, \"h3\").text\n",
    "            education.append(school)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Extract Skills\n",
    "    skills = []\n",
    "    try:\n",
    "        driver.get(profile_url + \"/details/skills/\")  # Navigate to skills section\n",
    "        time.sleep(random.uniform(4, 6))\n",
    "        skill_elements = driver.find_elements(By.XPATH, \"//span[contains(@class, 'skill-name')]\")\n",
    "        for skill in skill_elements:\n",
    "            skills.append(skill.text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        \"Name\": name,\n",
    "        \"Jobs\": \"; \".join(jobs),\n",
    "        \"Education\": \"; \".join(education),\n",
    "        \"Skills\": \"; \".join(skills),\n",
    "        \"Profile URL\": profile_url\n",
    "    }\n",
    "\n",
    "# ---------------- MAIN SCRIPT ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    EMAIL = \"your-email@example.com\"\n",
    "    PASSWORD = \"your-password\"\n",
    "\n",
    "    linkedin_login(EMAIL, PASSWORD)\n",
    "\n",
    "    job_titles = [\n",
    "        \"Software Developer\",\n",
    "        \"Software Engineer\",\n",
    "        \"Data Scientist\",\n",
    "        \"AI Engineer\",\n",
    "        \"Machine Learning Engineer\",\n",
    "        \"Backend Developer\",\n",
    "        \"Fronend Developer\",\n",
    "        \"Devops Engineer\",\n",
    "        \"QA Engineer\",\n",
    "        \"IT Administrator\",\n",
    "        \"System Administrator\",\n",
    "        \"Data Analyst\",\n",
    "        \"Full Stack Developer\",\n",
    "        \"Web Developer\",\n",
    "        \"System Architect\",\n",
    "        \"Cyber Security\",\n",
    "        \"SRE\",\n",
    "        \"Security Analyst\",\n",
    "        \"Cloud Architect\",\n",
    "        \"AI researcher\",\n",
    "        \"Automation Engineer\"\n",
    "    ]\n",
    "\n",
    "    all_profiles = []\n",
    "    for job in job_titles:\n",
    "        print(f\"üîç Searching for: {job}\")\n",
    "        profiles = search_profiles(job, num_pages=4)\n",
    "        all_profiles.extend(profiles)\n",
    "        time.sleep(random.uniform(5, 10))\n",
    "\n",
    "    # Remove duplicates\n",
    "    all_profiles = list(set(all_profiles))\n",
    "\n",
    "    # Scrape each profile\n",
    "    scraped_data = []\n",
    "    for profile_url in all_profiles[:10]:  # Limit to 10 profiles to avoid bans\n",
    "        data = scrape_profile(profile_url)\n",
    "        scraped_data.append(data)\n",
    "        print(f\"‚úÖ Scraped: {data['Name']} - {data['Jobs']}\")\n",
    "        time.sleep(random.uniform(5, 10))\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(scraped_data)\n",
    "    df.to_csv(\"linkedin_profiles.csv\", index=False)\n",
    "    print(\"‚úÖ Data saved to linkedin_profiles.csv\")\n",
    "\n",
    "    driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
